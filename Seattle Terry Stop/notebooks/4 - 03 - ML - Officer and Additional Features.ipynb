{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant packages for analysis\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_context('talk')\n",
    "import random\n",
    "from scipy.stats import randint\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "PROJ_ROOT = os.path.join(os.pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bryan Dickinson 2019-08-07 13:34:13 \n",
      "\n",
      "CPython 3.7.3\n",
      "IPython 7.7.0\n",
      "\n",
      "numpy 1.16.4\n",
      "pandas 0.25.0\n",
      "scikitlearn not installed\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a \"Bryan Dickinson\" -d -t -v -p numpy,pandas,scikitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the path to the data and read into a pandas dataframe\n",
    "\n",
    "terry_data = os.path.join(PROJ_ROOT, \n",
    "                         'data', 'processed',\n",
    "                         'Terry_Stops_Clean.csv')\n",
    "\n",
    "data = pd.read_csv(terry_data, parse_dates = ['date'], \n",
    "                   index_col = 'date', dtype = {'officer_race':'category','officer_gender':'category',\n",
    "                                                'subject_age':'category','subject_race':'category',\n",
    "                                                'subject_gender': 'category','stop_resolution': 'category',\n",
    "                                                'weapon_type':'category','initial_call_type':'category',\n",
    "                                                'call_type':'category','arrest':'int32', 'frisk':'float',\n",
    "                                                'precinct':'category', 'sector':'category', 'beat': 'category'})\n",
    "\n",
    "data.sort_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>officer_id</th>\n",
       "      <th>officer_age</th>\n",
       "      <th>officer_race</th>\n",
       "      <th>officer_gender</th>\n",
       "      <th>officer_squad</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>subject_age</th>\n",
       "      <th>subject_race</th>\n",
       "      <th>subject_gender</th>\n",
       "      <th>stop_resolution</th>\n",
       "      <th>weapon_type</th>\n",
       "      <th>initial_call_type</th>\n",
       "      <th>call_type</th>\n",
       "      <th>arrest</th>\n",
       "      <th>frisk</th>\n",
       "      <th>precinct</th>\n",
       "      <th>sector</th>\n",
       "      <th>beat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-03-15</th>\n",
       "      <td>115</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10305.0</td>\n",
       "      <td>1 - 17</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>GO for Prosecutorial Referral</td>\n",
       "      <td>Lethal Cutting Instrument</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-16</th>\n",
       "      <td>1757</td>\n",
       "      <td>31.0</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1432.0</td>\n",
       "      <td>18 - 25</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>Arrest with GO or Supplemental</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-16</th>\n",
       "      <td>1735</td>\n",
       "      <td>38.0</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20151.0</td>\n",
       "      <td>36 - 45</td>\n",
       "      <td>Multi-Racial</td>\n",
       "      <td>Male</td>\n",
       "      <td>Street Check</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-16</th>\n",
       "      <td>1735</td>\n",
       "      <td>38.0</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22667.0</td>\n",
       "      <td>18 - 25</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>Street Check</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-17</th>\n",
       "      <td>1735</td>\n",
       "      <td>38.0</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10743.0</td>\n",
       "      <td>26 - 35</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>Street Check</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            officer_id  officer_age        officer_race officer_gender  \\\n",
       "date                                                                     \n",
       "2015-03-15         115         60.0  Hispanic or Latino              M   \n",
       "2015-03-16        1757         31.0               White              M   \n",
       "2015-03-16        1735         38.0               White              M   \n",
       "2015-03-16        1735         38.0               White              M   \n",
       "2015-03-17        1735         38.0               White              M   \n",
       "\n",
       "           officer_squad  subject_id subject_age  subject_race subject_gender  \\\n",
       "date                                                                            \n",
       "2015-03-15           NaN     10305.0      1 - 17         Black         Female   \n",
       "2015-03-16           NaN      1432.0     18 - 25         Black           Male   \n",
       "2015-03-16           NaN     20151.0     36 - 45  Multi-Racial           Male   \n",
       "2015-03-16           NaN     22667.0     18 - 25         White           Male   \n",
       "2015-03-17           NaN     10743.0     26 - 35         White           Male   \n",
       "\n",
       "                           stop_resolution                weapon_type  \\\n",
       "date                                                                    \n",
       "2015-03-15   GO for Prosecutorial Referral  Lethal Cutting Instrument   \n",
       "2015-03-16  Arrest with GO or Supplemental                       None   \n",
       "2015-03-16                    Street Check                       None   \n",
       "2015-03-16                    Street Check                       None   \n",
       "2015-03-17                    Street Check                       None   \n",
       "\n",
       "           initial_call_type call_type  arrest  frisk precinct sector beat  \n",
       "date                                                                        \n",
       "2015-03-15               NaN       NaN       0    1.0      NaN    NaN  NaN  \n",
       "2015-03-16               NaN       NaN       1    0.0      NaN    NaN  NaN  \n",
       "2015-03-16               NaN       NaN       0    0.0      NaN    NaN  NaN  \n",
       "2015-03-16               NaN       NaN       0    0.0      NaN    NaN  NaN  \n",
       "2015-03-17               NaN       NaN       0    0.0      NaN    NaN  NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_mean(x):\n",
    "    #Function to split the Age bins and return the mean of the two numbers\n",
    "        if '-' in x:\n",
    "            split_list = x.split('-')\n",
    "            mean = (float(split_list[0]) + float(split_list[1]))/2\n",
    "        else:\n",
    "            mean = 56\n",
    "        return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2269 entries, 2015-03-18 to 2019-05-06\n",
      "Data columns (total 4 columns):\n",
      "officer_id           2269 non-null int64\n",
      "subject_race         2269 non-null category\n",
      "initial_call_type    2269 non-null category\n",
      "beat                 2269 non-null category\n",
      "dtypes: category(3), int64(1)\n",
      "memory usage: 53.9 KB\n"
     ]
    }
   ],
   "source": [
    "ofc_columns = ['officer_id','subject_race', 'call_type', 'initial_call_type', 'beat']\n",
    "\n",
    "df = data[ofc_columns]\n",
    "\n",
    "# view only stops when the officer initiates the stop\n",
    "df = df[df.call_type == 'ONVIEW']\n",
    "\n",
    "\n",
    "#remove ambiguous subject_races\n",
    "df = df[(df.subject_race != 'Unknown') & (df.subject_race != 'Other')]\n",
    "\n",
    "#subset the data to include the initial call types that prompted the stop, limit to 5 or more to capture any trends\n",
    "ls = list(df.initial_call_type.value_counts()[df.initial_call_type.value_counts() >= 5].index)\n",
    "df = df[df.initial_call_type.isin(ls)]\n",
    "\n",
    "#subset the data to include officers with at least 15 stops or more\n",
    "ls = list(df.officer_id.value_counts()[df.officer_id.value_counts() >= 15].index)\n",
    "df = df[df.officer_id.isin(ls)]\n",
    "df.head()\n",
    "\n",
    "df.drop(['call_type'], axis = 1, inplace = True) #drop the call type feature\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2253 entries, 2015-03-18 to 2019-05-06\n",
      "Data columns (total 4 columns):\n",
      "officer_id           2253 non-null int64\n",
      "subject_race         2253 non-null category\n",
      "initial_call_type    2253 non-null category\n",
      "beat                 2253 non-null category\n",
      "dtypes: category(3), int64(1)\n",
      "memory usage: 47.8 KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#create the pattern to match the beat entries\n",
    "pattern = re.compile( '^[A-Z][1-9]$')\n",
    "\n",
    "#drop any NaNs in the beat column\n",
    "df = df.dropna(subset = ['beat'])\n",
    "\n",
    "#use the pattern created to subset the data and get rid of the erroneous entries\n",
    "df = df[(df.beat.str.contains(pattern))]\n",
    "\n",
    "#remove all unused categories\n",
    "for col in df.select_dtypes(include = ['category']).columns:\n",
    "    df[col] = df[col].cat.remove_unused_categories()\n",
    "\n",
    "    #capture the category codes & corresponding strings for the 'race' classes\n",
    "race_cat_codes = dict(enumerate(df['subject_race'].cat.categories))\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>officer_id</th>\n",
       "      <th>subject_race</th>\n",
       "      <th>initial_call_type</th>\n",
       "      <th>beat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-03-18</th>\n",
       "      <td>1735</td>\n",
       "      <td>White</td>\n",
       "      <td>WARRANT - FELONY PICKUP</td>\n",
       "      <td>E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-18</th>\n",
       "      <td>1735</td>\n",
       "      <td>White</td>\n",
       "      <td>WARRANT - FELONY PICKUP</td>\n",
       "      <td>E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-18</th>\n",
       "      <td>1735</td>\n",
       "      <td>White</td>\n",
       "      <td>WARRANT - FELONY PICKUP</td>\n",
       "      <td>E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-18</th>\n",
       "      <td>1827</td>\n",
       "      <td>American Indian / Alaskan Native</td>\n",
       "      <td>TRAFFIC STOP - OFFICER INITIATED ONVIEW</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-18</th>\n",
       "      <td>1735</td>\n",
       "      <td>Black</td>\n",
       "      <td>WARRANT - FELONY PICKUP</td>\n",
       "      <td>E2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            officer_id                      subject_race  \\\n",
       "date                                                       \n",
       "2015-03-18        1735                             White   \n",
       "2015-03-18        1735                             White   \n",
       "2015-03-18        1735                             White   \n",
       "2015-03-18        1827  American Indian / Alaskan Native   \n",
       "2015-03-18        1735                             Black   \n",
       "\n",
       "                                  initial_call_type beat  \n",
       "date                                                      \n",
       "2015-03-18                  WARRANT - FELONY PICKUP   E2  \n",
       "2015-03-18                  WARRANT - FELONY PICKUP   E2  \n",
       "2015-03-18                  WARRANT - FELONY PICKUP   E2  \n",
       "2015-03-18  TRAFFIC STOP - OFFICER INITIATED ONVIEW   C2  \n",
       "2015-03-18                  WARRANT - FELONY PICKUP   E2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevent classifiers\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#import preprocessing, metrics & pipelines\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report,confusion_matrix, roc_curve, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The metric that will be used is log loss. log loss is a log function is a measure of error. \n",
    "#The error should be as small as possible.\n",
    "\n",
    "def compute_log_loss(predicted, actual, eps = 1e-14):\n",
    "    #computes the logarithmic loss between predicted and actual when these are 1d arrays\n",
    "    predicted = np.clip(predicted, eps, 1-eps)\n",
    "    loss = -1 * np.mean(actual * np.log(predicted)\n",
    "                       + (1 - actual)\n",
    "                       * np.log(1-predicted))\n",
    "    return loss\n",
    "\n",
    "def consolidate_array(arr, cols = [0,1,2,3,4,5]):\n",
    "    #function to transform the dummies array to a single column\n",
    "    \n",
    "    df = pd.DataFrame(arr, columns = cols)\n",
    "    return(df.idxmax(axis = 1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#set up the target variable\n",
    "y = pd.get_dummies(df['subject_race']).values\n",
    "\n",
    "\n",
    "#set the x variables by converting the categorical text features to dummy variables\n",
    "X = pd.get_dummies(df.reset_index(drop = True).drop(['subject_race'], axis = 1),\n",
    "                          columns = ['officer_id', 'beat', 'initial_call_type'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2253, 6)\n",
      "(2253, 190)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 46 candidates, totalling 230 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 230 out of 230 | elapsed:  3.7min finished\n",
      "C:\\Users\\Bryan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('sm',\n",
       "                                        SMOTE(k_neighbors=5, kind='deprecated',\n",
       "                                              m_neighbors='deprecated',\n",
       "                                              n_jobs=1, out_step='deprecated',\n",
       "                                              random_state=5, ratio=None,\n",
       "                                              sampling_strategy='not majority',\n",
       "                                              svm_estimator='deprecated')),\n",
       "                                       ('scale',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('clf',\n",
       "                                        One...\n",
       "                                                                                       n_estimators='warn',\n",
       "                                                                                       n_jobs=None,\n",
       "                                                                                       oob_score=False,\n",
       "                                                                                       random_state=5,\n",
       "                                                                                       verbose=0,\n",
       "                                                                                       warm_start=False),\n",
       "                                                      n_jobs=None)],\n",
       "                          'clf__estimator__criterion': ['gini'],\n",
       "                          'clf__estimator__max_depth': [4, 3, None],\n",
       "                          'clf__estimator__max_features': ['auto', 2, 4],\n",
       "                          'clf__estimator__n_estimators': [10, 25, 50, 100]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_log_loss', verbose=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the data to test & training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, \n",
    "                                                    random_state = 5, stratify = y)\n",
    "\n",
    "\n",
    "#build the pipline with upsampling & scaling the data\n",
    "pipeline = imbPipeline([('sm', SMOTE(random_state = 5, sampling_strategy = 'not majority')),\n",
    "                        ('scale', StandardScaler()),\n",
    "                        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "                       ])\n",
    "\n",
    "#paramters for tuning\n",
    "parameters = [\n",
    "    {'clf' : [ OneVsRestClassifier(LogisticRegression(random_state = 5))],\n",
    "    'clf__estimator__C' : np.logspace(-5, 8, 10),\n",
    "    'clf__estimator__solver' : ['lbfgs']},\n",
    "    {'clf' : [ OneVsRestClassifier(RandomForestClassifier(random_state = 5))],\n",
    "    'clf__estimator__max_depth':[4, 3, None],\n",
    "     'clf__estimator__criterion': ['gini'],\n",
    "    'clf__estimator__n_estimators' : [10,25,50,100],\n",
    "    'clf__estimator__max_features' : ['auto', 2, 4]},\n",
    "]\n",
    "\n",
    "#create the grid search object\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid = parameters,\n",
    "                    scoring = 'neg_log_loss', \n",
    "                    refit = True, \n",
    "                    cv = 5, \n",
    "                    verbose= True, \n",
    "                    n_jobs = -1)\n",
    "\n",
    "\n",
    "#fit the data\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'predict_race_model.sav'\n",
    "pickle.dump(cv, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('sm',\n",
       "                 SMOTE(k_neighbors=5, kind='deprecated',\n",
       "                       m_neighbors='deprecated', n_jobs=1,\n",
       "                       out_step='deprecated', random_state=5, ratio=None,\n",
       "                       sampling_strategy='not majority',\n",
       "                       svm_estimator='deprecated')),\n",
       "                ('scale',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('clf',\n",
       "                 OneVsRestClassifier(estimator=LogisticRegression(C=0.21544346900318823,\n",
       "                                                                  class_weight=None,\n",
       "                                                                  dual=False,\n",
       "                                                                  fit_intercept=True,\n",
       "                                                                  intercept_scaling=1,\n",
       "                                                                  l1_ratio=None,\n",
       "                                                                  max_iter=100,\n",
       "                                                                  multi_class='warn',\n",
       "                                                                  n_jobs=None,\n",
       "                                                                  penalty='l2',\n",
       "                                                                  random_state=5,\n",
       "                                                                  solver='lbfgs',\n",
       "                                                                  tol=0.0001,\n",
       "                                                                  verbose=0,\n",
       "                                                                  warm_start=False),\n",
       "                                     n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on the test set\n",
    "y_pred = cv.predict(X_test)\n",
    "\n",
    "y_predict_proba = cv.predict_proba(X_test)\n",
    "\n",
    "y_t = consolidate_array(y_test)\n",
    "y_p = consolidate_array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is: -1.3663228770811118\n",
      "The Log Loss score is: 0.3626715342134398\n",
      "[[ 11   0   2   0   0   1]\n",
      " [ 12   0   1   0   0   0]\n",
      " [119   0   9   0   0  12]\n",
      " [ 22   0   0   0   0   3]\n",
      " [ 15   0   1   0   0   0]\n",
      " [208   0   4   0   0  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.79      0.05        14\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.53      0.06      0.11       140\n",
      "           3       0.00      0.00      0.00        25\n",
      "           4       0.00      0.00      0.00        16\n",
      "           5       0.66      0.13      0.21       243\n",
      "\n",
      "    accuracy                           0.11       451\n",
      "   macro avg       0.20      0.16      0.06       451\n",
      "weighted avg       0.52      0.11      0.15       451\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#accuracy score\n",
    "acc_score = cv.score(X_test, y_test)\n",
    "log_loss = compute_log_loss(y_predict_proba, y_test)\n",
    "print('The accuracy score is: {}'.format(acc_score))\n",
    "print('The Log Loss score is: {}'.format(log_loss))\n",
    "\n",
    "\n",
    "#print the confusion matrix and classification report from the best model\n",
    "print(confusion_matrix(y_t, y_p))\n",
    "print(classification_report(y_t, y_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17736506860828938 \t American Indian / Alaskan Native\n",
      "0.16231245721799537 \t Asian\n",
      "0.6361940176404637 \t Black\n",
      "0.25306143445002266 \t Hispanic\n",
      "0.20350791630965773 \t Multi-Racial\n",
      "0.74358831105421 \t White\n"
     ]
    }
   ],
   "source": [
    "#print the log loss for each column\n",
    "for col in np.arange(0,6):\n",
    "    print( compute_log_loss(y_predict_proba[:,col], y_test[:,col]), '\\t',race_cat_codes[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002959</td>\n",
       "      <td>0.002958</td>\n",
       "      <td>0.168457</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>0.003262</td>\n",
       "      <td>0.829221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.089833</td>\n",
       "      <td>0.093844</td>\n",
       "      <td>0.237074</td>\n",
       "      <td>0.160303</td>\n",
       "      <td>0.143212</td>\n",
       "      <td>0.358930</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.089738</td>\n",
       "      <td>0.101733</td>\n",
       "      <td>0.250687</td>\n",
       "      <td>0.142971</td>\n",
       "      <td>0.154033</td>\n",
       "      <td>0.356270</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.048963</td>\n",
       "      <td>0.048972</td>\n",
       "      <td>0.276105</td>\n",
       "      <td>0.049546</td>\n",
       "      <td>0.063643</td>\n",
       "      <td>0.369992</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.084836</td>\n",
       "      <td>0.090499</td>\n",
       "      <td>0.258997</td>\n",
       "      <td>0.142892</td>\n",
       "      <td>0.129215</td>\n",
       "      <td>0.350853</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.098147</td>\n",
       "      <td>0.096516</td>\n",
       "      <td>0.254551</td>\n",
       "      <td>0.132966</td>\n",
       "      <td>0.151957</td>\n",
       "      <td>0.347619</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.199449</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>0.821889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.091648</td>\n",
       "      <td>0.106616</td>\n",
       "      <td>0.257991</td>\n",
       "      <td>0.129430</td>\n",
       "      <td>0.149395</td>\n",
       "      <td>0.350982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.095650</td>\n",
       "      <td>0.100934</td>\n",
       "      <td>0.240881</td>\n",
       "      <td>0.139235</td>\n",
       "      <td>0.151757</td>\n",
       "      <td>0.351420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.094725</td>\n",
       "      <td>0.104996</td>\n",
       "      <td>0.261266</td>\n",
       "      <td>0.136597</td>\n",
       "      <td>0.152919</td>\n",
       "      <td>0.355337</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5  0  1  2  3  4  \\\n",
       "0  0.002959  0.002958  0.168457  0.003289  0.003262  0.829221  0  0  0  1  0   \n",
       "1  0.089833  0.093844  0.237074  0.160303  0.143212  0.358930  0  0  0  0  0   \n",
       "2  0.089738  0.101733  0.250687  0.142971  0.154033  0.356270  0  0  0  0  0   \n",
       "3  0.048963  0.048972  0.276105  0.049546  0.063643  0.369992  0  0  0  0  0   \n",
       "4  0.084836  0.090499  0.258997  0.142892  0.129215  0.350853  0  0  0  1  0   \n",
       "5  0.098147  0.096516  0.254551  0.132966  0.151957  0.347619  1  0  0  0  0   \n",
       "6  0.002787  0.002892  0.199449  0.003024  0.003213  0.821889  0  0  0  0  0   \n",
       "7  0.091648  0.106616  0.257991  0.129430  0.149395  0.350982  0  0  0  0  0   \n",
       "8  0.095650  0.100934  0.240881  0.139235  0.151757  0.351420  0  0  0  0  0   \n",
       "9  0.094725  0.104996  0.261266  0.136597  0.152919  0.355337  1  0  0  0  0   \n",
       "\n",
       "   5  \n",
       "0  0  \n",
       "1  1  \n",
       "2  1  \n",
       "3  1  \n",
       "4  0  \n",
       "5  0  \n",
       "6  1  \n",
       "7  1  \n",
       "8  1  \n",
       "9  0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.DataFrame(y_predict_proba), pd.DataFrame(y_test)], axis = 1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beat_E3</th>\n",
       "      <td>-0.376671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beat_Q2</th>\n",
       "      <td>-0.330176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beat_D3</th>\n",
       "      <td>-0.307895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         importance\n",
       "beat_E3   -0.376671\n",
       "beat_Q2   -0.330176\n",
       "beat_D3   -0.307895"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#obtain the feature importances from within the GridSearchCV, pipeline, & OneVsRest objects\n",
    "feat_imp = [x.coef_ for x in cv.best_estimator_.steps[2][1].estimators_]\n",
    "feat_imp = np.mean(feat_imp, axis = 0)\n",
    "\n",
    "#place the feature importances in a dataframe\n",
    "feature_importances = pd.DataFrame(feat_imp[0],\n",
    "                                   index = X.columns,\n",
    "                                   columns=['importance']).sort_values('importance',ascending=True)\n",
    "feature_importances.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The model performance metrics:**\n",
    " - Log Loss .36\n",
    " - Precision .52\n",
    " - Recall .13\n",
    " - F1 Score .15\n",
    "    \n",
    "    The model is a small improvement from the previous model increasing Recall & the F1 Score, though is still not making predictions confidently enough to improve the F1 score to an acceptable level. We can see from predicted probabilities, the predictions are a bit more confident than the previous model. \n",
    "    The top 3 features are 'beat' locations and negative, suggesting that subjects stopped in these neighborhoods have a slightly higher probability of *not* being frisked.\n",
    "\n",
    "A Stop does not necessarily lead to a 'frisk', another set of behaviors observed by an experienced officer needs to be evaluated before a frisk is legitimately performed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
